/**
 * Copyright 2022,2023 Patrick R. Nicolas. All Rights Reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License"). You may not use this file except in compliance
 * with the License. A copy of the License is located at
 *
 * http://aws.amazon.com/apache2.0/
 *
 * or in the "license" file accompanying this file. This file is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES
 * OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions
 */
package org.bertspark.nlp.medical

import org.apache.spark.sql._
import org.bertspark.config.MlopsConfiguration.mlopsConfiguration
import org.bertspark.nlp.trainingset.{KeyedValues, TokenizedTrainingSet, TrainingSet}
import org.bertspark.classifier.dataset.ClassifierDataset
import org.bertspark.config.S3PathNames
import org.bertspark.modeling.TrainingLabelIndexing
import org.bertspark.util.io.S3Util


/**
 * Create a labeled DJL dataset from labeled training data loaded from S3 given a bucket and folder
 * {{{
 *   The DJL dataset is build using the
 *   - Labeled training data loaded from S3
 *   - CLS prediction generated by the BERT pre-trained model
 * }}}
 * @param tokenizedIndexedDS Data set of Tokenized indexed label data
 *                           TokenizedIndexedTrainingSet(ContextualDocument,label, labelIndex, embedding)
 * @param sparkSession Implicit reference to the Spark context
 *
 * @author Patrick Nicolas
 * @version 0.1
 */
private[bertspark] final class LabeledDjlDataset(
  tokenizedIndexedDS: Dataset[TokenizedTrainingSet],
  keyedPredictions: List[KeyedValues],
  subModelName: String
)(implicit sparkSession: SparkSession) {
  import sparkSession.implicits._

  private[this] val trainingSet = {
    val labelIndexMap = TrainingLabelIndexing.load
    TrainingSet(tokenizedIndexedDS, labelIndexMap)
  }

  private[this] val (_djlTrainingData, _djlValidationData) = {
    val trainValidateRatio = mlopsConfiguration.classifyConfig.trainValidateRatio
    trainingSet.toClassificationDjlDataset(trainValidateRatio, keyedPredictions, subModelName)
  }

  def getNumClasses: Long = trainingSet.getLabelIndexMap.size

  def size: Long = _djlTrainingData.size
  def djlTrainingData: Option[ClassifierDataset] =
    if(_djlTrainingData.size > 0) Some(_djlTrainingData) else None
  def djlValidationData: Option[ClassifierDataset] =
    if(_djlValidationData.size > 0) Some(_djlValidationData) else None

  @inline
  def getIndexLabelsMap: Map[Int, String] = trainingSet.indexLabelMap


  def getTokenizedIndexedTrainingSet: Seq[TokenizedTrainingSet] = tokenizedIndexedDS.collect

  def getKeyedPredictions: List[KeyedValues] = keyedPredictions

  def getSubModelName: String = subModelName
}


/**
  * Singleton for  saving the Deep Java Learning dataset
  */
private[bertspark] object LabeledDjlDataset {
  case class LabeledDjlDatasetRecord(subModel: String, keyedValues: Seq[KeyedValues])

  /**
    * Save the embeddings to a S3 folder
    *
    * @param labeledDjlDatasets Embeddings to be stored on S3
    */
  def save(labeledDjlDatasets: Seq[LabeledDjlDataset]): Unit = {
    import org.bertspark.implicits._
    import sparkSession.implicits._

    val labeledDjlDatasetRecordDS = labeledDjlDatasets.map(
      labeledDataset => LabeledDjlDatasetRecord(labeledDataset.getSubModelName, labeledDataset.getKeyedPredictions)
    ).toDS()

    S3Util.datasetToS3[LabeledDjlDatasetRecord](
      labeledDjlDatasetRecordDS,
      S3PathNames.getS3ClassifierEmbeddingsPath,
      header = false,
      fileFormat = "json",
      toAppend = true,
      numPartitions = 4
    )
  }
}
